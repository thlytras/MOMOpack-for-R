---
title: "Investigating delay correction"
author: "Richard White"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r eval=TRUE, include=FALSE}
devtools::load_all()
library(data.table)
library(ggplot2)

# Functions
TP <- function(var){
  sum(var=="TP",na.rm=T)
}

FP <- function(var){
  sum(var=="FP",na.rm=T)
}

TN <- function(var){
  sum(var=="TN",na.rm=T)
}

FN <- function(var){
  sum(var=="FN",na.rm=T)
}

PPV <- function(var){
  return(TP(var)/(TP(var)+FP(var)))
}

NPV <- function(var){
  return(TN(var)/(TN(var)+FN(var)))
}

SENS <- function(var){
  return(TP(var)/(TP(var)+FN(var)))
}

SPEC <- function(var){
  return(TN(var)/(TN(var)+FP(var)))
}


masterData <- fread("/docs/dashboards/data_raw/normomo/FHIDOD2_20180814.txt")
masterData[,DoD:=as.Date(as.character(DODS_DATO),format="%Y%m%d")]
masterData[,DoR:=as.Date(as.character(ENDR_DATO),format="%Y%m%d")]
masterData[,DoB:=as.Date(as.character(FDATO_YYYYMMDD),format="%Y%m%d")]
masterData[,age:=floor(as.numeric(difftime(DoD,DoB,units="days"))/365.25)]
masterData[is.na(DoR),DoR:=DoD+1]
masterData[DoR>="2015-09-03",DoR:=DoR+1]

masterData[,ageCat:=cut(age,c(0,4,14,64,200),include.lowest = TRUE)]
masterData[,deathWeek:=RAWmisc::WeekN(masterData$DoD)]
masterData[,deathYear:=RAWmisc::YearN(masterData$DoD)]
MDATA <- as.data.frame(masterData[!is.na(age),c("DoD","DoR","age")])

HDATA <- data.frame(readxl::read_excel(system.file("extdata", "bank_holidays.xlsx", package = "normomo"))[,c("date", "closed")])
HDATA$date <- as.Date(HDATA$date)

SetOpts(
  DoA=as.Date("2018-08-14"),
  DoPR=as.Date("2012-01-01"),
  WStart=1,
  WEnd=52,
  country = "Norway",
  source = "FHI",
  MDATA = MDATA,
  HDATA = HDATA,
  INPUTDIR = tempdir(),
  WDIR = tempdir(),
  back = 7,
  WWW = 290,
  Ysum = 2018,
  Wsum = 40,
  USEglm2 = TRUE,
  useAUTOMN = TRUE,
  datesISO = FALSE,
  plotGraphs = FALSE,
  delayVersion = "original",
  MOMOgroups = list("Total"="age >= 0 | is.na(age)"),
  MOMOmodels = list("Total"="LINE_SIN"))

x <- BenchmarkDelay()

d <- x[delayVersion %in% c("original","original+season"),c(
  "YoDi","WoDi","delayVersion","nb","zscore",
  "predzscore0","predzscore1","predzscore2","predzscore3","predzscore4","predzscore5",
  "pred0","pred1","pred2","pred3","pred4","pred5",
  "WR0","WR1","WR2","WR3","WR4","WR5"
  )]
setnames(d,c("predzscore0","predzscore1","predzscore2","predzscore3","predzscore4","predzscore5"),c("pzscore0","pzscore1","pzscore2","pzscore3","pzscore4","pzscore5"))
d <- melt.data.table(d[delayVersion=="original"],id.vars=c("YoDi","WoDi","delayVersion","nb","zscore"),measure=patterns("^pzscore","^pred","^WR"))
setnames(d,c("value1","value2","value3"),c("pzscore","pnb","WR"))
d[,delay:=as.numeric(variable)-1]

d[,error_pnb:=pnb-nb]

d[,truePos:=zscore>2]
d[,testPos:=pzscore>2]

d[,test_results:=as.character(NA)]
d[truePos==TRUE & testPos==TRUE, test_results:="TP"]
d[truePos==FALSE & testPos==FALSE, test_results:="TN"]
d[truePos==FALSE & testPos==TRUE, test_results:="FP"]
d[truePos==TRUE & testPos==FALSE, test_results:="FN"]

```

## Number of deaths recorded per week

```{r echo=TRUE, fig.height=5, fig.width=7, message=FALSE, warning=FALSE}
q <- ggplot(d,aes(x=delay,y=WR/nb*100,group=delay))
q <- q + geom_boxplot()
q <- q + scale_x_continuous("Lag")
q <- q + scale_y_continuous("Percent of deaths recorded")
q
```

## Raw correlations

Here we investigate the correlation between:

1. The true number of recorded deaths and the predicted deaths for lags of between 0 and 5 weeks
2. The true zscore and the predicted zscore (i.e. the z-score calculated using the predicted number of deaths) for lags of between 0 and 5 weeks

```{r echo=TRUE, message=FALSE, warning=FALSE}
d[,.(
  corr_nb=cor(nb,pnb,use="pairwise.complete.obs"),
  corr_zscore=cor(zscore,pzscore,use="pairwise.complete.obs")
),keyby=.(delayVersion,delay)]
```

You can see that for a lag of 0 week, there is extremely minimal correlation between the predicted number of recorded deaths and the true number of recorded deaths. For a lag of 1 week, there is a negative correlation between the true z-score and the predicted z-score.

These results improve for a lag of 1 week, but are still not good. With a lag of 2 or more weeks, the results seem to be acceptable.

```{r echo=TRUE, fig.height=5, fig.width=7, message=FALSE, warning=FALSE}
q <- ggplot(d,aes(x=pzscore,y=zscore))
q <- q + geom_point()
q <- q + facet_grid(delayVersion~delay,scales="free")
q <- q + scale_x_continuous("Z-score using predicted number of deaths at different lags")
q <- q + scale_y_continuous("True Z-score")
q
```

```{r echo=TRUE, fig.height=5, fig.width=7, message=FALSE, warning=FALSE}
q <- ggplot(d,aes(x=pnb,y=nb))
q <- q + geom_point()
q <- q + facet_grid(delayVersion~delay,scales="free")
q <- q + scale_x_continuous("Predicted number of deaths at different lags")
q <- q + scale_y_continuous("True number of recorded deaths")
q
```

We see that the graphs reinforce these findings. Poor performance in lag 0, bad performance in lag 1, and acceptable-to-good performance for lag 2+.

## Performances for excess mortality alerts

We now need to investigate the performance of the alerts. That is, if excess mortality is detected in lag 0, is this actually a true alert?

Here we present the raw numbers, where `truePos` represents if it is a true excess mortality event or not, and `testPos` represents if the predicted number of deaths created an excess mortality alert or not:

```{r echo=TRUE, message=FALSE, warning=FALSE}
xtabs(~d$truePos+d$testPos+d$delay)
```

We now list the number of true positives `tp`, true negatives `tn`, false positives `fp`, false negatives `fp`, and the positive predictive value `ppv`, negative predictive value `npv`, sensitivity `sens`, and specificity `spec`.

```{r echo=TRUE, message=FALSE, warning=FALSE}
results <- d[,.(
  tp=TP(test_results),
  tn=TN(test_results),
  fp=FP(test_results),
  fn=FN(test_results),
  ppv=RAWmisc::Format(PPV(test_results)*100,0),
  npv=RAWmisc::Format(NPV(test_results)*100,0),
  sens=RAWmisc::Format(SENS(test_results)*100,0),
  spec=RAWmisc::Format(SPEC(test_results)*100,0)
),keyby=.(delay)]

print(results)
```

We can see that the performance for lags of 0 and 1 week is poor, while lags of 2+ are acceptable.

## Biases

We now plot the bias (predicted number of deaths minus actual number of deaths) against the true Z-score for different lags.

```{r echo=TRUE, fig.height=5, fig.width=7, message=FALSE, warning=FALSE}
q <- ggplot(d,aes(x=zscore,y=error_pnb))
q <- q + geom_point()
q <- q + facet_grid(delayVersion~delay,scales="free")
q <- q + scale_x_continuous("True Z-Score")
q <- q + scale_y_continuous("Bias (predicted number of deaths minus actual number of deaths)")
q
```

We see that in lags 0 and 1 there is a severe tendency to overestimate the number of deaths when there are less than normal (i.e. leading to false positives) and a severe tendency to underestimate the number of deaths when there are more deaths than normal (i.e. leading to false negatives). This explains the poor findings in the "Performances for excess mortality alerts" section.

We do not observe noticeable biases in lags 2+.

